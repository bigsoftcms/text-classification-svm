<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE us-patent-grant SYSTEM "us-patent-grant-v42-2006-08-23.dtd" [ ]>
<us-patent-grant lang="EN" dtd-version="v4.2 2006-08-23" file="US07641475-20100105.XML" status="PRODUCTION" id="us-patent-grant" country="US" date-produced="20091221" date-publ="20100105">
<us-bibliographic-data-grant>
<publication-reference>
<document-id>
<country>US</country>
<doc-number>07641475</doc-number>
<kind>B2</kind>
<date>20100105</date>
</document-id>
</publication-reference>
<application-reference appl-type="utility">
<document-id>
<country>US</country>
<doc-number>11313962</doc-number>
<date>20051222</date>
</document-id>
</application-reference>
<us-application-series-code>11</us-application-series-code>
<priority-claims>
<priority-claim sequence="01" kind="national">
<country>JP</country>
<doc-number>2005-283789</doc-number>
<date>20050929</date>
</priority-claim>
</priority-claims>
<us-term-of-grant>
<us-term-extension>568</us-term-extension>
</us-term-of-grant>
<classifications-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>09</class>
<subclass>B</subclass>
<main-group>3</main-group>
<subgroup>00</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20100105</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
</classifications-ipcr>
<classification-national>
<country>US</country>
<main-classification>434322</main-classification>
<further-classification>434323</further-classification>
<further-classification>434350</further-classification>
<further-classification>434353</further-classification>
</classification-national>
<invention-title id="d0e71">Program, method and apparatus for generating fill-in-the-blank test questions</invention-title>
<references-cited>
<citation>
<patcit num="00001">
<document-id>
<country>US</country>
<doc-number>5141439</doc-number>
<kind>A</kind>
<name>Cousins</name>
<date>19920800</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>434178</main-classification></classification-national>
</citation>
<citation>
<patcit num="00002">
<document-id>
<country>US</country>
<doc-number>6302698</doc-number>
<kind>B1</kind>
<name>Ziv-El</name>
<date>20011000</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>434323</main-classification></classification-national>
</citation>
<citation>
<patcit num="00003">
<document-id>
<country>US</country>
<doc-number>6632096</doc-number>
<kind>B1</kind>
<name>Sumimoto</name>
<date>20031000</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>434322</main-classification></classification-national>
</citation>
<citation>
<patcit num="00004">
<document-id>
<country>US</country>
<doc-number>6766066</doc-number>
<kind>B2</kind>
<name>Kitazawa</name>
<date>20040700</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382291</main-classification></classification-national>
</citation>
<citation>
<patcit num="00005">
<document-id>
<country>US</country>
<doc-number>7341352</doc-number>
<kind>B2</kind>
<name>Katsuyama</name>
<date>20080300</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>353 42</main-classification></classification-national>
</citation>
<citation>
<patcit num="00006">
<document-id>
<country>JP</country>
<doc-number>05019163</doc-number>
<date>19930100</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00007">
<document-id>
<country>JP</country>
<doc-number>06095583</doc-number>
<date>19940400</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00008">
<document-id>
<country>JP</country>
<doc-number>07302036</doc-number>
<date>19951100</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00009">
<document-id>
<country>JP</country>
<doc-number>08274646</doc-number>
<date>19961000</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00010">
<document-id>
<country>JP</country>
<doc-number>2000148079</doc-number>
<date>20000500</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00011">
<document-id>
<country>JP</country>
<doc-number>2001188792</doc-number>
<date>20010700</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00012">
<document-id>
<country>JP</country>
<doc-number>2003173129</doc-number>
<kind>A</kind>
<date>20030600</date>
</document-id>
</patcit>
<category>cited by examiner</category>
</citation>
<citation>
<patcit num="00013">
<document-id>
<country>JP</country>
<doc-number>2003248417</doc-number>
<date>20030900</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00014">
<othercit>Nakano et al., Unified Presentation Contents Retrieval Using Laser Pointer Information, Apr. 4, 2005, IEEE Computer Society, Proceedings of the 21st International Conference on Data Engineering (ICDE '05), pp. 1-3.</othercit>
</nplcit>
<category>cited by examiner</category>
</citation>
</references-cited>
<number-of-claims>16</number-of-claims>
<us-exemplary-claim>1</us-exemplary-claim>
<us-field-of-classification-search>
<classification-national>
<country>US</country>
<main-classification>434322</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>434323</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>434350</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>434353</main-classification>
</classification-national>
</us-field-of-classification-search>
<figures>
<number-of-drawing-sheets>17</number-of-drawing-sheets>
<number-of-figures>17</number-of-figures>
</figures>
<us-related-documents>
<related-publication>
<document-id>
<country>US</country>
<doc-number>20070072164</doc-number>
<kind>A1</kind>
<date>20070329</date>
</document-id>
</related-publication>
</us-related-documents>
<parties>
<applicants>
<applicant sequence="001" app-type="applicant-inventor" designation="us-only">
<addressbook>
<last-name>Katsuyama</last-name>
<first-name>Yutaka</first-name>
<address>
<city>Kawasaki</city>
<country>JP</country>
</address>
</addressbook>
<nationality>
<country>omitted</country>
</nationality>
<residence>
<country>JP</country>
</residence>
</applicant>
<applicant sequence="002" app-type="applicant-inventor" designation="us-only">
<addressbook>
<last-name>Ozawa</last-name>
<first-name>Noriaki</first-name>
<address>
<city>Kawasaki</city>
<country>JP</country>
</address>
</addressbook>
<nationality>
<country>omitted</country>
</nationality>
<residence>
<country>JP</country>
</residence>
</applicant>
<applicant sequence="003" app-type="applicant-inventor" designation="us-only">
<addressbook>
<last-name>Naoi</last-name>
<first-name>Satoshi</first-name>
<address>
<city>Kawasaki</city>
<country>JP</country>
</address>
</addressbook>
<nationality>
<country>omitted</country>
</nationality>
<residence>
<country>JP</country>
</residence>
</applicant>
</applicants>
<agents>
<agent sequence="01" rep-type="attorney">
<addressbook>
<orgname>Staas &#x26; Halsey LLP</orgname>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
</agents>
</parties>
<assignees>
<assignee>
<addressbook>
<orgname>Fujitsu Limited</orgname>
<role>03</role>
<address>
<city>Kawasaki</city>
<country>JP</country>
</address>
</addressbook>
</assignee>
</assignees>
<examiners>
<primary-examiner>
<last-name>Mosser</last-name>
<first-name>Kathleen</first-name>
<department>3715</department>
</primary-examiner>
<assistant-examiner>
<last-name>Fletcher</last-name>
<first-name>Jerry-Daryl</first-name>
</assistant-examiner>
</examiners>
</us-bibliographic-data-grant>
<abstract id="abstract">
<p id="p-0001" num="0000">A pointing information extraction unit extracts pointing information indicating a pointing position and a pointing time on a slide from a slide file used in a lecture and a video file of a lecture video using a pointing device. A word information generation unit analyzes a text sentence extracted from the slide file to generate a word information file indicating a word and a position thereof. A word pointing information generation unit estimates a word closest to the pointing position on the slide to generate a word pointing information file with the pointing time assigned. A fill-in-the-blank word extraction unit extracts a word having a pointing time equal to or longer than a predetermined time from the word pointing information as a fill-in-the-blank word file. A fill-in-the-blank test question is generated by setting the fill-in-the-blank word of the slide information as a blank region.</p>
</abstract>
<drawings id="DRAWINGS">
<figure id="Fig-EMI-D00000" num="00000">
<img id="EMI-D00000" he="101.68mm" wi="160.36mm" file="US07641475-20100105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00001" num="00001">
<img id="EMI-D00001" he="162.64mm" wi="135.04mm" orientation="landscape" file="US07641475-20100105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00002" num="00002">
<img id="EMI-D00002" he="234.70mm" wi="159.09mm" orientation="landscape" file="US07641475-20100105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00003" num="00003">
<img id="EMI-D00003" he="244.09mm" wi="180.59mm" file="US07641475-20100105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00004" num="00004">
<img id="EMI-D00004" he="243.50mm" wi="178.99mm" file="US07641475-20100105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00005" num="00005">
<img id="EMI-D00005" he="237.32mm" wi="163.15mm" orientation="landscape" file="US07641475-20100105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00006" num="00006">
<img id="EMI-D00006" he="205.82mm" wi="178.14mm" orientation="landscape" file="US07641475-20100105-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00007" num="00007">
<img id="EMI-D00007" he="253.49mm" wi="176.11mm" orientation="landscape" file="US07641475-20100105-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00008" num="00008">
<img id="EMI-D00008" he="250.95mm" wi="172.55mm" orientation="landscape" file="US07641475-20100105-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00009" num="00009">
<img id="EMI-D00009" he="232.66mm" wi="182.54mm" orientation="landscape" file="US07641475-20100105-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00010" num="00010">
<img id="EMI-D00010" he="216.83mm" wi="177.55mm" orientation="landscape" file="US07641475-20100105-D00010.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00011" num="00011">
<img id="EMI-D00011" he="113.20mm" wi="143.26mm" file="US07641475-20100105-D00011.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00012" num="00012">
<img id="EMI-D00012" he="244.77mm" wi="165.44mm" orientation="landscape" file="US07641475-20100105-D00012.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00013" num="00013">
<img id="EMI-D00013" he="152.06mm" wi="175.18mm" file="US07641475-20100105-D00013.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00014" num="00014">
<img id="EMI-D00014" he="258.40mm" wi="179.92mm" orientation="landscape" file="US07641475-20100105-D00014.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00015" num="00015">
<img id="EMI-D00015" he="199.14mm" wi="141.73mm" file="US07641475-20100105-D00015.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00016" num="00016">
<img id="EMI-D00016" he="177.97mm" wi="140.46mm" file="US07641475-20100105-D00016.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00017" num="00017">
<img id="EMI-D00017" he="179.66mm" wi="129.46mm" file="US07641475-20100105-D00017.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
</drawings>
<description id="description">
<?BRFSUM description="Brief Summary" end="lead"?>
<heading id="h-0001" level="1">CROSS-REFERENCE TO RELATED APPLICATION</heading>
<p id="p-0002" num="0001">This application claims the benefit of priority to prior application No. JP 2005-283789, filed Sep. 29, 2005 in Japan, of which full contents are incorporated herein by reference.</p>
<heading id="h-0002" level="1">BACKGROUND OF THE INVENTION</heading>
<p id="p-0003" num="0002">1. Field of the Invention</p>
<p id="p-0004" num="0003">The present invention relates generally to a program, method and apparatus for generating fill-in-the-blank test questions by replacing a portion of a presentation material such as a slide used for a lecture with blanks, and more particularly, to a program, method and apparatus for automatically generating fill-in-the-blank test questions by coordinating with a video of a lecture using a pointing tool such as a laser pointer for the presentation material.</p>
<p id="p-0005" num="0004">2. Description of the Related Art</p>
<p id="p-0006" num="0005">In fields of in-company training and a general education, e-learning is increasingly introduced. The e-learning is a remote-area education using the internet and is often performed using a web screen. Since a lecturer cannot check reactions of students in the e-learning, a test is usually conducted on the web screen after the learning on the web screen. In order to generate the web test content, a large amount of man-hours is needed since the content is generated by an expert who understands details of the content with consideration of importance of the details. On the other hand, in the web content in the form of using a lecture video, a lecturer usually spends more time describing an important portion during shooting of the lecture. If the important portion described for a longer time can be automatically extracted from the material used in the lecture, test questions can be automatically generated.</p>
<p id="p-0007" num="0006">The following is known as prior art for generating such fill-in-the-blank test questions.</p>
<p id="p-0008" num="0007">(1) After any characters of a document shown on a screen are turned to unprinted characters with simple operation of a pointing device, the unprinted characters are displayed and checked with simple operation.</p>
<p id="p-0009" num="0008">(2) A region of a target character string for rote learning is specified from a displayed document with a rote-learning assistance apparatus and a medium pen storing a rote-learning assistance program.</p>
<p id="p-0010" num="0009">(3) With a mask edit unit, without editing (changing) an educational material which already exist, apparent changes can be made by performing mask setting to any regions of the educational material only for any time period (patent document 3). Therefore, while enhancing reusability, mask-style questions can be easily generated and a learner can make apparent changes without editing the educational material.</p>
<p id="p-0011" num="0010">(4) For example, if &#x201c;Succeeding Nobnaga Oda, Hideyoshi Toyotomi destroyed Hojo-shi in Odawara and dominated the whole country in 1590&#x201d; is input as a learning target sentence, words with word-class information of personal names, place names and numeric characters are randomly selected from this sentence to automatically generate a question sentence, answer fields and right answers of fill-in-the-blank questions. Therefore, a workload for generating questions can be reduced and, if a learner studies using this apparatus, a practical ability can be obtained and a learning effect can be expected.</p>
<p id="p-0012" num="0011">However, in such conventional fill-in-the-blank test question generation, a user specifies fill-in-the-blank portions manually while watching a screen and fill-in-the-blank test questions are not automatically generated. In (1), only the portions specified on the screen by the user with a mouse pointer and the like are switched to be displayed or not, and it takes a lot of man-hours to manually generate test questions. In (2), the fill-in-the-blank portions are instructed on the screen with a pen, and it takes a lot of man-hours since test questions are generated manually. In (3), only the portions specified on the screen by the user with a mouse pointer and the like are switched to be displayed or not, and it takes a lot of man-hours to generate test questions since the fill-in-the-blank portions are manually specified by the user. Also, in conventional fill-in-the-blank test question generation, although the fill-in-the-blank test questions can be automatically generated from a lecture material, suitable questions cannot be generated since fill-in-the-blank portions are generated from portions which is not considered as important by a lecturer. In other words, in (4), words with word-class information of personal names, place names and numeric characters are randomly selected from a text to automatically generate a question sentence, answer fields and right answers of fill-in-the-blank questions, and importance of fill-in-the-blank items considered by the lecturer is not determined. On the other hand, the applicant of the present invention has been developed an automatic generation technology for the content which synchronizes and regenerates on the web a video recording a lecture and a slide used in the lecture and a technology for automatically generating from a lecture video the content which regenerates on the web the laser-pointer information in a lecture using a laser pointer (Japanese Patent Application No. 2004-569359). In the web content in the form of using a lecture video, a lecturer usually spends more time describing an important portion during shooting of the lecture. If the important portion described for a longer time can be automatically extracted from the material used in the lecture, test questions can be automatically generated.</p>
<heading id="h-0003" level="1">SUMMARY OF THE INVENTION</heading>
<p id="p-0013" num="0012">According to the present invention there are provided a program, method and apparatus for automatically generating suitable fill-in-the-blank test questions by determining important portions of slide information used in a lecture from pointing portions of a laser pointer and the like in a lecture video. In order to achieve the above object, the present invention is configured as follows.</p>
<p id="p-0014" num="0013">(Program)</p>
<p id="p-0015" num="0014">The present invention provides a fill-in-the-blank test question generation program operable to drive a computer to execute:</p>
<p id="p-0016" num="0015">a pointing information extraction step of extracting pointing information indicating a pointing position and a pointing time on a slide from slide information used in a lecture and a video image of the lecture using a pointing device;</p>
<p id="p-0017" num="0016">a word information generation step of analyzing text information extracted from the slide information to generate word information indicating a word and a position thereof;</p>
<p id="p-0018" num="0017">a word pointing information generation step of estimating a word closest to the pointing position on the slide to generate word pointing information with the pointing time assigned;</p>
<p id="p-0019" num="0018">a fill-in-the-blank word extraction step of extracting a word having a pointing time equal to or longer than a predetermined time from the word pointing information as a fill-in-the-blank word; and</p>
<p id="p-0020" num="0019">a test question generation step of setting the fill-in-the-blank word of the slide information as a blank region to generate a fill-in-the-blank test question.</p>
<p id="p-0021" num="0020">The word information generation step performs a morpheme analysis of the text information to generate the word information indicating a word and a position thereof.</p>
<p id="p-0022" num="0021">The pointing information extraction step:</p>
<p id="p-0023" num="0022">identifies a correspondence relationship with the slide information for each video frame of the video information;</p>
<p id="p-0024" num="0023">detects a display time of each slide by grouping video frames for each of the slides using the identified corresponding relationship; and</p>
<p id="p-0025" num="0024">extracts pointing information indicating pointing positions and pointing clock times on the slides by extracting pointing positions and extracting pointing clock times for each of the slides, which are converted into pointing positions on the identified slides.</p>
<p id="p-0026" num="0025">The pointing information extraction step extracts a bright point of a laser pointer, a mouse cursor interlocked with mouse operation on a personal computer, a tip portion of a pointing stick and a hand or fingertip of a lecturer existing in video information, as a pointing position. The pointing information extraction step detects a word closest to a pointing position for each slide, assigns a pointing time and aggregates pointing clock times of the same word to generate a pointing time for each word. The test question generation step extracts a fill-in-the-blank word satisfying predetermined constraint conditions from the fill-in-the-blank word information to generate a fill-in-the-blank test question. The test question generation step selects fill-in-the-blank characters by setting the constraint conditions as at least one of:</p>
<p id="p-0027" num="0026">being equal to or smaller than the number of fill-in-the-blank words set per line;</p>
<p id="p-0028" num="0027">not being adjacent to a preceding fill-in-the-blank word; and</p>
<p id="p-0029" num="0028">being equal to or smaller than the number of fill-in-the-blank words set per slide page.</p>
<p id="p-0030" num="0029">If the number of the fill-in-the-blank words is limited to a predetermined number or less by the constraint conditions, the test question generation step selects the fill-in-the-blank words equal to or smaller than the predetermined number in accordance with predetermined priority conditions. The test question generation step selects fill-in-the-blank characters by setting the priority conditions as at least one of:</p>
<p id="p-0031" num="0030">giving priority to a noun; or</p>
<p id="p-0032" num="0031">giving priority to a predefined character type among character types such as English, katakana, kanji, hiragana and the like.</p>
<p id="p-0033" num="0032">(Method)</p>
<p id="p-0034" num="0033">The present invention provides a fill-in-the-blank test question generation method comprising:</p>
<p id="p-0035" num="0034">a pointing information extraction step of extracting pointing information indicating a pointing position and a pointing time on a slide from slide information used in a lecture and a video image of the lecture using a pointing device;</p>
<p id="p-0036" num="0035">a word information generation step of analyzing text information extracted from the slide information to generate word information indicating a word and a position thereof;</p>
<p id="p-0037" num="0036">a word pointing information generation step of estimating a word closest to the pointing position on the slide to generate word pointing information with the pointing time assigned;</p>
<p id="p-0038" num="0037">a fill-in-the-blank word extraction step of extracting a word having a pointing time equal to or longer than a predetermined time from the word pointing information as a fill-in-the-blank word; and</p>
<p id="p-0039" num="0038">a test question generation step of setting the fill-in-the-blank word of the slide information as a blank region to generate a fill-in-the-blank test question.</p>
<p id="p-0040" num="0039">(Apparatus)</p>
<p id="p-0041" num="0040">The present invention provides a fill-in-the-blank test question generation apparatus comprising:</p>
<p id="p-0042" num="0041">a pointing information extraction unit extracting pointing information indicating a pointing position and a pointing time on a slide from slide information used in a lecture and a video image of the lecture using a pointing device;</p>
<p id="p-0043" num="0042">a word information generation unit analyzing text information extracted from the slide information to generate word information indicating a word and a position thereof;</p>
<p id="p-0044" num="0043">a word pointing information generation unit estimating a word closest to the pointing position on the slide to generate word pointing information with the pointing time assigned;</p>
<p id="p-0045" num="0044">a fill-in-the-blank word extraction unit extracting a word having a pointing time equal to or longer than a predetermined time from the word pointing information as a fill-in-the-blank word; and</p>
<p id="p-0046" num="0045">a test question generation unit setting the fill-in-the-blank word of the slide information as a blank region to generate a fill-in-the-blank test question.</p>
<p id="p-0047" num="0046">Details of the method and the apparatus of the fill-in-the-blank test question generation according to the present invention are basically the same as the case of the program for generating the fill-in-the-blank test questions of the present invention. According to the present invention, since in web content in the form of using video of a lecture using a slide, a lecturer usually spends more time describing an important portion during shooting of the lecture using the slide and the important portion of the slide is pointed with the use of a laser pointer or the like many times, by automatically extracting the important portion within a sentence on the slide from pointing information of the laser pointer or the like in the lecture video and by replacing a word of the important portion with a blank, a fill-in-the-blank test question can be automatically generated which is suitable for determining whether the content of the lecture has been learned or not; automatic generation can be achieved for fill-in-the-blank test questions which are conventionally generated by the lecturer separately from the lecture slide; time and effort is reduced as compared to artificial generation; and costs can be considerably reduced. Also, once the lecture being recorded on a video is ended, suitable fill-in-the-blank questions in conformity with the lecture content can be rapidly generated from the lecture video, which can be useful for checking a level of understanding of students by timely offering a brief test to the students. The above and other objects, features and advantages of the present invention will become more apparent from the following detailed description with reference to the drawings.</p>
<?BRFSUM description="Brief Summary" end="tail"?>
<?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?>
<description-of-drawings>
<heading id="h-0004" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading>
<p id="p-0048" num="0047"><figref idref="DRAWINGS">FIG. 1</figref> is an explanatory view of a use environment of a fill-in-the-blank test question generation apparatus according to the present invention;</p>
<p id="p-0049" num="0048"><figref idref="DRAWINGS">FIG. 2</figref> is a block diagram of a hardware configuration of the fill-in-the-blank test question generation apparatus according to the present invention;</p>
<p id="p-0050" num="0049"><figref idref="DRAWINGS">FIGS. 3A and 3B</figref> are block diagrams of a functional configuration of the fill-in-the-blank test question generation apparatus according to the present invention;</p>
<p id="p-0051" num="0050"><figref idref="DRAWINGS">FIG. 4</figref> is an explanatory view of a slide file used in the present invention;</p>
<p id="p-0052" num="0051"><figref idref="DRAWINGS">FIG. 5</figref> is an explanatory view of a lecture video used in the present invention;</p>
<p id="p-0053" num="0052"><figref idref="DRAWINGS">FIGS. 6A and 6B</figref> are explanatory views of a procedure of fill-in-the-blank test question generation processing of the present invention;</p>
<p id="p-0054" num="0053"><figref idref="DRAWINGS">FIG. 7</figref> is an explanatory view of a procedure of the fill-in-the-blank test question generation processing continued from <figref idref="DRAWINGS">FIGS. 6A and 6B</figref>;</p>
<p id="p-0055" num="0054"><figref idref="DRAWINGS">FIG. 8</figref> is an explanatory view of processing for generating pointing information from video frames for each slide;</p>
<p id="p-0056" num="0055"><figref idref="DRAWINGS">FIG. 9</figref> is an explanatory view of processing for generating word pointing information from word information and pointing information;</p>
<p id="p-0057" num="0056"><figref idref="DRAWINGS">FIG. 10</figref> is an explanatory view of detection processing for distance between a word and a pointer of <figref idref="DRAWINGS">FIG. 9</figref>;</p>
<p id="p-0058" num="0057"><figref idref="DRAWINGS">FIG. 11</figref> is an explanatory view of a display screen of the fill-in-the-blank test questions generated according to the present invention;</p>
<p id="p-0059" num="0058"><figref idref="DRAWINGS">FIG. 12</figref> is a flowchart of the fill-in-the-blank test question generation processing according to the present invention; and</p>
<p id="p-0060" num="0059"><figref idref="DRAWINGS">FIG. 13</figref> is a flowchart of the word pointing information generation processing in step S<b>8</b> of <figref idref="DRAWINGS">FIG. 12</figref>.</p>
</description-of-drawings>
<?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?>
<?DETDESC description="Detailed Description" end="lead"?>
<heading id="h-0005" level="1">DETAILED DESCRIPTION OF THE PREFERRED EMBODIMENT</heading>
<p id="p-0061" num="0060"><figref idref="DRAWINGS">FIG. 1</figref> is an explanatory view of an example of a use environment of an apparatus for generating fill-in-the-blank test questions according to the present invention. In <figref idref="DRAWINGS">FIG. 1</figref>, a fill-in-the-blank test question generation apparatus <b>10</b> according to the present invention is constituted by an information processing apparatus, for example, a personal computer. The processing of the fill-in-the-blank test question generation apparatus <b>10</b> requires lecture-video information and slide information used in a lecture. Therefore, a video camera <b>12</b> shoots a lecture of a lecturer <b>16</b> using a slide <b>14</b> and a pointing device such as a laser pointer <b>18</b>. The lecture image shot by the video camera <b>12</b> includes an image of a laser spot (a bright spot) <b>20</b> pointed with the laser pointer <b>18</b> used by the lecturer <b>16</b> for describing the slide <b>14</b>. In such a lecture using the slide <b>14</b>, since the lecturer <b>16</b> spends more time describing an important portion of the slide <b>14</b> and the important portion is described while being pointed with the laser pointer <b>18</b> many times at the time of the description, therefore, the important portion described for a longer time by the lecturer <b>16</b> can be determined from a image state of the laser spot <b>20</b> due to the laser pointer <b>18</b> on the slide <b>14</b>. The video information shot by the video camera <b>12</b> is converted into the AVI (Audio Video Interleaving) format or the like and is stored into the fill-in-the-blank test question generation apparatus <b>10</b>. Also, a slide file <b>22</b> such as a PowerPoint&#xae; file is input to the fill-in-the-blank test question generation apparatus <b>10</b> as the slide information used in the lecture. After inputting such video information from the video camera <b>12</b> and the slide file <b>22</b> used in the lecture, portions described for a longer time by the lecturer <b>16</b> in the lecture are determined as important portions and a fill-in-the-blank test question file <b>24</b> is automatically generated with those portions blanked. The slide file used here includes text sentences <b>25</b>-<b>1</b>, <b>25</b>-<b>2</b> and <b>25</b>-<b>3</b>, and for the slide file <b>22</b> which was projected on the slide <b>14</b> in the lecture, since the lecturer <b>16</b> uses the laser pointer <b>18</b> to point important portions in the text sentences <b>25</b>-<b>1</b> to <b>25</b>-<b>3</b> with the laser spot <b>20</b>, the important portions are determined from detection information of the laser spot <b>20</b> in the video image and the fill-in-the-blank test question file <b>24</b> is generated by forming blanks <b>26</b>-<b>1</b> and <b>26</b>-<b>2</b> in the fill-in-the-blank test question file <b>24</b>.</p>
<p id="p-0062" num="0061"><figref idref="DRAWINGS">FIG. 2</figref> is a block diagram of a hardware configuration of the fill-in-the-blank test question generation apparatus <b>10</b> according to the present invention. In <figref idref="DRAWINGS">FIG. 2</figref>, the fill-in-the-blank test question generation apparatus <b>10</b> connects a bus <b>30</b> of a CPU <b>28</b> with a video input control unit <b>32</b>, a memory <b>34</b> such as a RAM, a device interface <b>36</b> connecting a display <b>38</b>, keyboard and mouse <b>42</b>, a program HDD (hard disk device) <b>44</b>, a data HDD <b>46</b>, a morpheme analysis dictionary HDD <b>48</b> and a file input/output unit <b>50</b>. The video input control unit <b>32</b> is externally connected with the video camera <b>12</b>, and the video images of the lecture shot by the video camera <b>12</b> as shown in <figref idref="DRAWINGS">FIG. 1</figref> are accumulated as a video file though the video input control unit <b>32</b> into the data HDD <b>46</b> in the AVI format and the like. On the other hand, the file input/output unit <b>50</b> is connected with the slide file <b>22</b> such as the power pointer used in the lecture and the slide file <b>22</b> is stored in the data HDD <b>46</b> through the file input/output unit <b>50</b>. In the program HDD <b>46</b>, a fill-in-the-blank test question generation program according to the present invention is installed as an application program. Such a fill-in-the-blank test question generation apparatus <b>10</b> is realized by a hardware environment of a personal computer. When the fill-in-the-blank test question generation apparatus <b>10</b> is activated, i.e., when reading out to the memory <b>34</b> and executing the fill-in-the-blank test question generation program in the program HDD <b>44</b> installed as an application program in a computer, the stored video information of the lecture and slide information used in the lecture are read into the memory <b>34</b> to determine portions described for a longer time by the lecturer in the lecture as important portions; the fill-in-the-blank test questions are generated with the portions blanked; and the generated fill-in-the-blank test questions are converted into, for example, the HTML format and stored in the fill-in-the-blank test question file <b>24</b>.</p>
<p id="p-0063" num="0062"><figref idref="DRAWINGS">FIGS. 3A and 3B</figref> are block diagrams of a functional configuration of the fill-in-the-blank test question generation apparatus <b>10</b> according to the present invention and the functions are realized by the CPU <b>28</b> executing the fill-in-the-blank test question generation program loaded from the program HDD <b>45</b> to the memory <b>34</b>. In FIGS. SA and SB, the fill-in-the-blank test question generation apparatus <b>10</b> is provided with an application execution environment <b>52</b> for executing the fill-in-the-blank test question generation program. The application execution environment <b>52</b> is provided with a video file <b>54</b>, a pointing information extraction unit <b>56</b>, a pointing information file <b>58</b>, a word information generation unit <b>60</b>, a word information file <b>64</b>, a word pointing information generation unit <b>65</b>, a word pointing information file <b>66</b>, a fill-in-the-blank question word extraction unit <b>68</b>, a fill-in-the-blank question word file <b>70</b>, a test question generation unit <b>72</b> and a constraint condition file <b>71</b>. Although a slide file is provided by the data HDD <b>46</b> of <figref idref="DRAWINGS">FIG. 2</figref> for the word information generation unit <b>60</b> as is the case with the video file <b>54</b>, this file is omitted since this file has the same content as the external slide file <b>22</b>. Also, for the word information generation unit <b>60</b>, a morpheme analysis dictionary file <b>62</b> is provided externally. From the slide file <b>22</b> used in the lecture and the video information of the lecture of the video file <b>54</b> using the pointing device, the pointing information extraction unit <b>56</b> extracts the pointing information indicating pointing positions on the slide and pointing time for each slide, which is stored into the pointing information file <b>58</b>. For each slide used in the lecture, the word information generation unit <b>60</b> extracts text information from the slide and obtains words and position coordinates thereof by executing a morpheme analysis based on the morpheme analysis dictionary file <b>62</b> for the extracted text information, which are stored into the word information file <b>64</b>. The word pointing information generation unit <b>65</b> reads the pointing information and the word information for each slide from the pointing information file <b>58</b> and the word information file <b>64</b>, estimates a word closest to the pointing position on the slide and generates the word pointing information assigned with the pointing time, which is stored into the word pointing information file <b>66</b>. Once the word pointing information is generated, the pointing time of the pointing with the laser pointer has been obtained for each word in the slide and the longer pointing time represents the important portion described by the lecturer for a longer time. The fill-in-the-blank question word extraction unit <b>68</b> reads the word pointing information from the word pointing information file <b>66</b> for each slide, extracts as a fill-in-the-blank word a word having the pointing time equal to or longer than a predetermined time defined in advance, i.e., equal to or longer than a threshold value indicating a predetermined importance level from the pointing time assigned to each word in the word pointing information and stores the word into the fill-in-the-blank question word file <b>70</b>. The test question generation unit <b>72</b> reads the fill-in-the-blank words for each slide from the fill-in-the-blank question word file <b>70</b>, sets the regions of the fill-in-the-blank words of the slide information to blank regions to generate fill-in-the-blank test questions which is converted into, for example, the HTML format and which is output to the fill-in-the-blank test question file <b>24</b> as the fill-in-the-blank test question content. For the test question generation unit <b>72</b>, the constraint condition file <b>71</b> is provided and the fill-in-the-blank test question can be generated using constraint conditions stored in the constraint condition file <b>71</b>. The constraint conditions stored in the constraint condition file <b>71</b> are as follows:</p>
<p id="p-0064" num="0063">(1) Being equal to or smaller than a predetermined number of the fill-in-the-blank words set per line;</p>
<p id="p-0065" num="0064">(2) Not being adjacent to a preceding fill-in-the-blank word; and</p>
<p id="p-0066" num="0065">(3) Being equal to or smaller than a predetermined number of the fill-in-the-blank words set per slide page.</p>
<p id="p-0067" num="0066">Also, priority conditions are set to the constraint condition file <b>71</b>. With these conditions, when the number of the fill-in-the-blank words per slide page or per line is limited to a predetermined number, in the case such that a multiplicity of candidate fill-in-the-blank words exists and has the same pointing time, priority is set for extracting the words which satisfy the limited number. For example, the priority is set as follows:</p>
<p id="p-0068" num="0067">(1) Giving priority to a noun; and</p>
<p id="p-0069" num="0068">(2) Giving priority to a predefined character type among character types such as English, katakana, kanji, hiragana and the like. For example, a word in katakana is prioritized over words in kanji and hiragana.</p>
<p id="p-0070" num="0069">Such constraint conditions and priority conditions in the constraint condition file <b>71</b> can be reflected to the test question generation processing by setting suitable constraint conditions and priority conditions as desired, based on the lecture contents for which questions are generated, a level of students and the intention of the lecturer.</p>
<p id="p-0071" num="0070"><figref idref="DRAWINGS">FIG. 4</figref> is an explanatory view of a slide file used in the lecture, which is the target of the processing of the present invention. In <figref idref="DRAWINGS">FIG. 4</figref>, a slide file <b>22</b> is, for example, a PowerPoint&#xae; file and text sentences <b>25</b> are displayed on the slide.</p>
<p id="p-0072" num="0071"><figref idref="DRAWINGS">FIG. 5</figref> is a video image of the lecture using the slide file <b>22</b> of <figref idref="DRAWINGS">FIG. 4</figref>. In <figref idref="DRAWINGS">FIG. 5</figref>, a video image <b>74</b> is one (1) scene of the lecture of the lecturer <b>16</b> using the slide <b>14</b> shot by the video camera <b>12</b> as shown in <figref idref="DRAWINGS">FIG. 1</figref>, and a slide image <b>76</b> is projected in the video image <b>74</b>. When the slide file <b>22</b> of <figref idref="DRAWINGS">FIG. 4</figref> and the video image <b>74</b> of <figref idref="DRAWINGS">FIG. 5</figref> are input to the fill-in-the-blank test question generation apparatus <b>10</b> of <figref idref="DRAWINGS">FIGS. 3A and 3B</figref> to generate the fill-in-the-blank test question by extracting the important portion described for a longer time by the lecturer based on positions pointed with the laser spot of the laser pointer, a slide image <b>76</b> is clipped out from the video image <b>74</b> of <figref idref="DRAWINGS">FIG. 5</figref> by image processing; after processing is performed for synchronizing the slide file <b>22</b> of <figref idref="DRAWINGS">FIG. 4</figref> and the slide image <b>76</b> as image information, the pointing information is generated from the slide image <b>76</b>; the word information is also generated from the slide file <b>22</b> of <figref idref="DRAWINGS">FIG. 4</figref>; the word pointing information is extracted by coupling both pieces of the information; and the test question is generated by extracting a word with the longer pointing time as the fill-in-the-blank word.</p>
<p id="p-0073" num="0072"><figref idref="DRAWINGS">FIGS. 6A and 6B</figref> and <figref idref="DRAWINGS">FIG. 7</figref> are explanatory views showing a procedure of the fill-in-the-blank test question generation processing of the present invention in accordance with the functions of the application execution environment <b>52</b> provided in the fill-in-the-blank test question generation apparatus <b>10</b> of <figref idref="DRAWINGS">FIGS. 3A and 3B</figref>. In <figref idref="DRAWINGS">FIGS. 6A and 6B</figref>, first, processing is performed by the word information generation unit <b>60</b> of <figref idref="DRAWINGS">FIGS. 3A and 3B</figref>. The word information generation unit <b>60</b> reads, for example, three (3) target slide files <b>22</b>-<b>1</b> to <b>22</b>-<b>3</b>, extracts text information from each of the slide files <b>22</b>-<b>1</b> to <b>22</b>-<b>3</b> and executes text information extraction processing <b>80</b> for generating text information files <b>82</b>-<b>1</b> to <b>82</b>-<b>3</b>. For each of the text information files <b>82</b>-<b>1</b> to <b>82</b>-<b>3</b>, morpheme analysis processing <b>84</b> is performed using the morpheme analysis dictionary file <b>62</b> to generate word information files <b>64</b>-<b>1</b> to <b>64</b>-<b>3</b> for each slide. The word information files <b>64</b>-<b>1</b> to <b>64</b>-<b>3</b> store words obtained from the morpheme analysis of the text information extracted from each slide and the coordinate position thereof. On the other hand, the pointing information extraction unit <b>56</b> of <figref idref="DRAWINGS">FIGS. 3A and 3B</figref> reads the slide files <b>22</b>-<b>1</b> to <b>22</b>-<b>3</b> and video frames <b>78</b>-<b>1</b> to <b>78</b>-<b>3</b> as the video information having the content of the lecture where the slide files are used and executes correspondence processing <b>88</b> of both. The correspondence processing <b>88</b> makes correspondence of (identifies) the video frame <b>78</b>-<b>1</b> to <b>78</b>-<b>3</b> showing each of the slide files <b>22</b>-<b>1</b> to <b>22</b>-<b>3</b>. The correspondence processing <b>88</b> generates a correspondence information file <b>90</b> identifying the correspondence relationship between the video frames and slides. Subsequently, for the correspondence information file <b>90</b>, display time detection processing <b>92</b> is performed for each slide to generate a slide display time file <b>94</b>. The detection of the slide display time detects the total time of all the frame times of the video frames belonging to each slide for the correspondence information file <b>90</b>. Further, the pointing information extraction unit <b>56</b> executes pointing information detection processing <b>95</b> of <figref idref="DRAWINGS">FIGS. 6A and 6B</figref> to generate a pointing information file <b>58</b>-<b>1</b> to <b>58</b>-<b>3</b> for each slide. For example, taking the slide file <b>22</b>-<b>1</b> as an example, the pointing information detection processing <b>95</b> extracts pointing coordinates and a clock time thereof of the spot of the laser pointer in each of the video frame <b>78</b>-<b>1</b> to <b>78</b>-n corresponding to the slide file <b>22</b>-<b>1</b> and converts the pointing coordinates on the video frame into the coordinates on the slide. As a result of the processing, the coordinates (slide coordinates) are output as the pointing information for each slide.</p>
<p id="p-0074" num="0073"><figref idref="DRAWINGS">FIG. 8</figref> shows details of the pointing information detection processing <b>95</b> of <figref idref="DRAWINGS">FIGS. 6A and 6B</figref>. In <figref idref="DRAWINGS">FIG. 8</figref>, for video frames <b>78</b>-<b>1</b> to <b>78</b>-<b>3</b><i>n</i>, by the correspondence processing, the slide <b>22</b>-<b>1</b> is made correspond to the video frame <b>78</b>-<b>1</b> to <b>78</b>-n; the slide <b>22</b>-<b>2</b> is made correspond to the video frame <b>78</b>-(n+1) to <b>78</b>-<b>2</b><i>n</i>; and the slide <b>22</b>-<b>3</b> is made correspond to the video frame <b>78</b>-(<b>2</b><i>n&#x2212;</i>1) to <b>78</b>-<b>3</b><i>n</i>. After the identification making the correspondence between the video frames <b>78</b>-<b>1</b> to <b>78</b>-<b>3</b><i>n </i>and the slides <b>22</b>-<b>1</b> to <b>22</b>-<b>3</b>, for the slides <b>22</b>-<b>1</b> to <b>22</b>-<b>3</b>, display times <b>100</b>-<b>1</b> to <b>100</b>-<b>3</b> of the slides <b>22</b>-<b>1</b> to <b>22</b>-<b>3</b> are detected from frame clock times t<b>1</b> to t<b>3</b><i>n </i>of the corresponding video frames <b>78</b>-<b>1</b> to <b>78</b>-<b>3</b><i>n</i>. The display time T<b>1</b> of the slide <b>22</b>-<b>1</b> is the time from the start clock time t<b>1</b> to the end clock time tn of the corresponding frames. The display time T<b>2</b> of the slide <b>22</b>-<b>2</b> is the time from the corresponding frame clock time tn+1 to the end clock time t<b>2</b><i>n</i>. The display time T<b>3</b> of the slide <b>22</b>-<b>3</b> is the time from the corresponding frame clock time t<b>2</b><i>n+</i>1 to the flame clock time t<b>3</b><i>n</i>. Further, for each slide <b>22</b>-<b>1</b> to <b>22</b>-<b>3</b>, the pointing information file <b>58</b>-<b>1</b> to <b>58</b>-<b>3</b> is generated for each of pointers P<b>1</b> to P<b>3</b><i>n </i>of the laser pointer taken as images in the corresponding video frames <b>78</b>-<b>1</b> to <b>78</b>-<b>3</b><i>n</i>. For example, taking the video frames <b>78</b>-<b>1</b> and <b>78</b>-<b>2</b> made correspond to the slide <b>22</b>-<b>1</b> as an example, the coordinates of the pointer P<b>1</b> of the laser pointer is (x<b>1</b>, y<b>1</b>) and a clock time t<b>1</b> is stored. For the next video frame <b>78</b>-<b>2</b>, the coordinates of the point P<b>2</b> (x<b>2</b>, y<b>2</b>) and a clock time t<b>2</b> of the coordinates are stored. Although the video frames <b>78</b>-<b>1</b> to <b>78</b>-<b>3</b><i>n </i>of <figref idref="DRAWINGS">FIG. 8</figref> are an example in the case that all the frames shows the pointer of the laser pointer, this is for the purpose of facilitating the description, and in the actual video images, the pointer may be shown or not shown depending on the situation of the lecture, of course.</p>
<p id="p-0075" num="0074">Referring again to <figref idref="DRAWINGS">FIGS. 6A and 6B</figref>, once the word information files <b>64</b>-<b>1</b> to <b>64</b>-<b>3</b> and the pointing information files <b>58</b>-<b>1</b> to <b>58</b>-<b>3</b> are generated for each slide by the processing of the word information generation unit <b>60</b> and the pointing information extraction unit <b>56</b> of <figref idref="DRAWINGS">FIGS. 3A and 3B</figref>, the procedure moves to processing of <figref idref="DRAWINGS">FIG. 7</figref>. <figref idref="DRAWINGS">FIG. 7</figref> shows a-processing procedure of the word pointing information generation unit <b>65</b> and the fill-in-the-blank question word extraction unit <b>68</b> of <figref idref="DRAWINGS">FIGS. 3A and 3B</figref>. First, the word pointing information generation unit <b>65</b> reads the word information files <b>64</b>-<b>1</b> to <b>64</b>-<b>3</b> and the pointing information files <b>58</b>-<b>1</b> to <b>58</b>-<b>3</b> generated for each slide, executes word pointing information generation processing <b>96</b> and generates word pointing information files <b>66</b>-<b>1</b>, <b>66</b>-<b>1</b> and <b>66</b>-<b>3</b>.</p>
<p id="p-0076" num="0075"><figref idref="DRAWINGS">FIGS. 9A and 9B</figref> show details of the word pointing information generation processing <b>96</b>. <figref idref="DRAWINGS">FIG. 9A</figref> shows the pointing information file <b>58</b>-<b>1</b> and the word information file <b>64</b>-<b>1</b> on the slide <b>22</b>-<b>1</b> for the purpose of facilitating the description, and the slide <b>22</b>-<b>1</b> shows words W<b>1</b> to W<b>7</b>, which are the content of the word information file <b>64</b>-<b>1</b>, and the pointers P<b>1</b> to P<b>6</b> of the pointing information file <b>58</b>-<b>1</b>. <figref idref="DRAWINGS">FIG. 9B</figref> is a procedure of generation processing for the word pointing information based on the slide <b>22</b>-<b>1</b>. In <figref idref="DRAWINGS">FIG. 9B</figref>, the pointing information <b>58</b>-<b>1</b> stores coordinates PP<b>1</b> to PP<b>6</b> on the slide <b>22</b>-<b>1</b> and pointing times t<b>1</b> to t<b>6</b> for the pointers P<b>1</b> to P<b>6</b>. On the other hand, the words W<b>1</b> to W<b>7</b> and the coordinates WP<b>1</b> to WP<b>7</b> of the words are registered into the word information file <b>64</b>-<b>1</b>. Therefore, based on the pointing information file <b>58</b>-<b>1</b> and the word information file <b>68</b>-<b>1</b>, the arrangement of the words W<b>1</b> to W<b>7</b> and the arrangement of the pointers P<b>1</b> to P<b>6</b> can be obtained as shown on the slide <b>22</b>-<b>1</b> of <figref idref="DRAWINGS">FIG. 9A</figref>. Then, in the order of the pointer P<b>1</b> to P<b>6</b>, a word closest to each pointer is determined. In this example, the pointers P<b>1</b> and P<b>2</b> are closest to the word W<b>1</b>; the pointer P<b>3</b> is closest to the word W<b>2</b>; the pointer P<b>4</b> is closest to the word W<b>6</b>; and the pointers P<b>5</b> and P<b>6</b> are closest to the word W<b>7</b>. Therefore, from these relationships, pointer/word correspondence information <b>102</b> of <figref idref="DRAWINGS">FIG. 9B</figref> is generated as intermediate working information. For the pointer/word correspondence information <b>102</b>, by grouping the times of the same word together and by combining the coordinates of the word with this, word pointing information <b>68</b>-<b>1</b> is generated. The word pointing information file <b>66</b>-<b>1</b> is constituted by words, coordinates and times and groups the clock times when pointed by the laser pointer, which specifically are the frame clock times, for each word. Since the frame clock time has a certain time interval, each clock time t<b>1</b> to t<b>6</b> can be handled as a frame unit time. Assuming that the frame unit time is T, conversion to time can be achieved as (t<b>1</b>, t<b>2</b>)=2T; t<b>3</b>=T; t<b>4</b>=T; and (t<b>5</b>, t<b>6</b>)=2T. When generating the word pointing information file <b>66</b>-<b>1</b>, the distance between the pointer and the word is detected as shown in <figref idref="DRAWINGS">FIG. 10</figref>, for example.</p>
<p id="p-0077" num="0076"><figref idref="DRAWINGS">FIG. 10</figref> shows the case of disposing a word <b>104</b> on a slide <b>22</b>-<b>11</b>, the word <b>104</b> has coordinates with two (2) coordinate points on the upper left corner and the lower right corner as coordinates of a word region. By having the coordinates with two (2) points on the upper left corner and the lower right corner, a rectangular region of the word <b>104</b> can be identified. Around the word <b>104</b>, eight (8) regions <b>106</b> to <b>120</b> are formed which are divided vertically and horizontally by dashed lines. For the regions <b>108</b>, <b>112</b>, <b>116</b> and <b>120</b> outside of each side of the rectangular region of the word <b>104</b>, the distances are detected for perpendicular lines extended to the sides from the pointers P<b>2</b>, P<b>4</b>, P<b>6</b> and P<b>8</b> existing in those regions. On the other hand, for the regions <b>106</b>, <b>110</b>, <b>114</b> and <b>118</b> corresponding to the corners of the word <b>104</b>, the distances are detected for a line which connects each corner with the pointers P<b>1</b>, P<b>3</b>, P<b>5</b> and P<b>7</b> existing in those regions.</p>
<p id="p-0078" num="0077"><figref idref="DRAWINGS">FIG. 11</figref> is an explanatory view of a display screen of the fill-in-the-blank test questions generated according to the present invention. In <figref idref="DRAWINGS">FIG. 11</figref>, the fill-in-the-blank test question screen <b>122</b> displays the fill-in-the-blank test questions <b>124</b> generated according to the present invention. For the fill-in-the-blank test questions <b>124</b>, words, i.e., important portions, described for a longer time by the lecturer are extracted based on the laser spot of the laser pointer recorded in the video information from the slide file <b>22</b> used in the lecture shown in <figref idref="DRAWINGS">FIG. 4</figref>, and the extracted words are blanked and assigned with (question <b>1</b>) to (question <b>5</b>) in this example. To the right of the fill-in-the-blank test questions <b>124</b>, a dialog of relative words <b>126</b> are displayed as clues. On the underside of the fill-in-the-blank test questions <b>124</b>, an answer field is provided. In the answer field, a fill-in space of an answer is provided for each of question <b>1</b>, question <b>2</b>, question <b>3</b>, question <b>4</b> and question <b>5</b>. Also, as shown on the right of &#x201c;answer of question <b>1</b>&#x201d;, the answer field can be an answer field of a selection question, such as &#x201c;A: WWW, B: WBT, C: Internet, C: CBT&#x201d;. In this fill-in-the-blank test questions <b>124</b>, since the constraint condition is not set by the constraint condition file <b>71</b> of <figref idref="DRAWINGS">FIGS. 3A and 3B</figref>, the questions are consecutively assigned in one (1) line, for example, with regard to (question <b>1</b>) and (question <b>2</b>). Also, the fill-in-the-blank test questions <b>124</b> may not be provided with the relevant words <b>126</b> and the answer field <b>128</b> and may be in a question format such that the portions of (question <b>1</b>) to (question <b>5</b>) are simple blank fields such as parentheses or a box where answers can be directly written in.</p>
<p id="p-0079" num="0078"><figref idref="DRAWINGS">FIGS. 12A and 12B</figref> are flowcharts of the fill-in-the-blank test questions generation processing according to the present invention, which is described with reference to <figref idref="DRAWINGS">FIGS. 3A and 3B</figref> as follows. First, in step Si, the slide file <b>22</b> is read into the word information generation unit <b>60</b> via the file input/output unit <b>50</b> and, in step S<b>2</b>, the text information is extracted for each slide. Then, in step S<b>3</b>, the morpheme analysis is performed for the text information of each slide based on the morpheme analysis dictionary file <b>62</b> and, in step S<b>4</b>, the word information file <b>64</b> is generated. Then, in step S<b>5</b>, the lecture video file is read into the pointing information extraction unit <b>56</b> from the video file <b>54</b> and, in step S<b>6</b>, the correspondence information of video frames and slides and the slide display time information are generated. Then, in step S<b>7</b>, the pointing coordinates and the pointing clock times are detected for each frame to generate the pointing information converting the pointing coordinates into the slide coordinates, which is stored into the pointing information file <b>58</b>. At this point, the word information generation processing of steps S<b>1</b> to S<b>4</b> may be executed concurrently with the pointing information generation processing of steps S<b>5</b> to S<b>7</b> as parallel processing. Then, in step S<b>8</b>, the word pointing information is generated by the word pointing information generation unit <b>65</b> and is stored into the word pointing information file <b>66</b>. Then, in step S<b>9</b>, the fill-in-the-blank question word extraction unit <b>68</b> extracts words equal to or greater than a threshold value from the word pointing information and, in step S<b>10</b>, the fill-in-the-blank question word file <b>70</b> is generated for each slide. Then, in step S<b>11</b>, refinement processing of the fill-in-the-blank words is performed for the fill-in-the-blank question word file <b>70</b> based on the constraint conditions in the constraint condition file <b>71</b> if desired. Then, in step S<b>12</b>, the test question generation unit <b>72</b> converts the positions on the slide of the fill-in-the-blank words obtained for each slide into blanks, parentheses or (question <b>1</b>), (question <b>2</b>) and the like to generate the fill-in-the-blank test question generations. In step S<b>13</b>, the fill-in-the-blank test questions are converted into, for example, the HTML format and are output to the fill-in-the-blank test question file <b>24</b>.</p>
<p id="p-0080" num="0079"><figref idref="DRAWINGS">FIG. 13</figref> is a flowchart showing details of the processing of the word pointing information generation unit <b>65</b> of <figref idref="DRAWINGS">FIGS. 3A and 3B</figref> in step S<b>8</b> of <figref idref="DRAWINGS">FIGS. 12A and 12B</figref>. In <figref idref="DRAWINGS">FIG. 13</figref>, the word pointing information generation unit <b>65</b> reads the word information for each slide from the word information file <b>64</b> in step S<b>1</b>, reads the pointing information for each slide from the pointing information file <b>58</b> in step S<b>2</b> and detects a word closest to the pointer to generate the pointer/word correspondence information which is assigned with the clock time of the word as the working information in step S<b>3</b>. Then, in step S<b>4</b>, the word pointing information is generated which aggregates clock times of the same word in the pointer/word correspondence information. Then, in step S<b>5</b>, it is checked whether the all the slides are processed or not, and the processing of steps S<b>1</b> to S<b>5</b> is repeated until all the slides are processed. Details of the word pointing information generation processing of steps S<b>1</b> to S<b>5</b> correspond to the processing procedure of <figref idref="DRAWINGS">FIG. 9</figref>.</p>
<p id="p-0081" num="0080">The present invention further provides a fill-in-the-blank test question generation program executed by a computer and the program has the content in accordance with flowcharts of <figref idref="DRAWINGS">FIGS. 12A and 12B</figref> and <figref idref="DRAWINGS">FIG. 13</figref>.</p>
<p id="p-0082" num="0081">The present invention further provides a computer readable recording medium storing the fill-in-the-blank test question generation program. The recording medium includes a portable recording medium such as a CD-ROM, floppy disk FD&#xae;, DVD disk, magnetic optical disk and IC card, and a storage device such as a hard disk HDD provided inside or outside of a computer system, a database keeping a program through a line, another computer system, a PC and a database thereof, or a transmission medium on a line. In the embodiment described above, although a laser pointer is taken as an example of the pointing device, in other cases, a stick used by the lecturer or a hand or fingertip of the lecturer may be extracted from the video image as a pointer and the pointing information may be extracted which indicates pointing positions and pointing clock times thereof. Also, in some cases of the lecture using the slide, a personal computer is connected with a projector, and a slide screen such as the PowerPoint&#xae; is displayed on the personal computer to display the slide with the projector in an interlocked manner. In this case, since a mouse is displayed on the slide while operating the mouse on the personal computer screen, by generating the pointing information targeting the mouse pointer, the present invention can be directly applied to the lecture video recording the screen where the slide application is operated with the mouse button. Further, although the video image is input in the embodiment described above, the pointing information may be extracted by inputting data recording the operation information of each of the slide operation and the mouse button operation on the computer. In this case, since the coordinates and clock times of the pointer are not needed to be extracted from the video frames, the processing can be simplified. Also, in the embodiment described above, the generated fill-in-the-blank test questions are converted into the HTML format to be output, the present invention is not limited to this and the questions can be converted to any formats such as a text document or a Word document to be output as long as the format can represent the test questions and can be output not only as web test questions but also as a printed paper document. The present invention encompasses appropriate modifications without impairing the object and advantages thereof and is not limited by the numeric values shown in the embodiment described above.</p>
<?DETDESC description="Detailed Description" end="tail"?>
</description>
<us-claim-statement>What is claimed is:</us-claim-statement>
<claims id="claims">
<claim id="CLM-00001" num="00001">
<claim-text>1. A computer readable storage medium which stores a fill-in-the-blank test question generation program operable to drive a computer to execute:
<claim-text>a pointing information extraction step of extracting pointing information indicating a pointing position and a pointing time on a slide from slide information used in a lecture and a video image of the lecture using a pointing device;</claim-text>
<claim-text>a word information generation step of analyzing text information extracted from the slide information to generate word information indicating a word and a position thereof;</claim-text>
<claim-text>a word pointing information generation step of estimating a word closest to the pointing position on the slide to generate word pointing information with the pointing time assigned;</claim-text>
<claim-text>a fill-in-the-blank word extraction step of extracting a word having a pointing time equal to or longer than a predetermined time from the word pointing information as a fill-in-the-blank word; and</claim-text>
<claim-text>a test question generation step of setting the fill-in-the-blank word of the slide information as a blank region to generate a fill-in-the-blank test question,</claim-text>
<claim-text>wherein the test question generation step extracts a fill-in-the-blank word satisfying predetermined constraint conditions from the fill-in-the-blank word information to generate a fill-in-the-blank test question,</claim-text>
<claim-text>wherein the test question generation step selects fill-in-the-blank characters by setting the constraint conditions as at least one of:</claim-text>
<claim-text>being equal to or smaller than the number of fill-in-the-blank words set per line;</claim-text>
<claim-text>not being adjacent to a preceding fill-in-the-blank word; and</claim-text>
<claim-text>being equal to or smaller than the number of fill-in-the-blank words set per slide page.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00002" num="00002">
<claim-text>2. The storage medium according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the word information generation step performs a morpheme analysis of the text information to generate the word information indicating a word and a position thereof.</claim-text>
</claim>
<claim id="CLM-00003" num="00003">
<claim-text>3. The storage medium according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the pointing information extraction step:
<claim-text>identifies a correspondence relationship with the slide information for each video frame of the video information;</claim-text>
<claim-text>detects a display time of each slide by grouping video frames for each of the slides using the identified corresponding relationship; and</claim-text>
<claim-text>extracts pointing information indicating pointing positions and pointing clock times on the slides by extracting pointing positions and extracting pointing clock times for each of the slides, which are converted into pointing positions on the identified slides.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00004" num="00004">
<claim-text>4. The storage medium according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the pointing information extraction step extracts a pointing position comprising a location of a bright point of a laser pointer, a mouse cursor interlocked with mouse operation on a personal computer, a tip portion of a pointing stick and a hand or fingertip of a lecturer existing in video information.</claim-text>
</claim>
<claim id="CLM-00005" num="00005">
<claim-text>5. The storage medium according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the pointing information extraction step detects a word closest to a pointing position for each slide, assigns a pointing time and aggregates pointing clock times of the same word to generate a pointing time for each word.</claim-text>
</claim>
<claim id="CLM-00006" num="00006">
<claim-text>6. The storage medium according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein if the number of the fill-in-the-blank words is limited to a predetermined number or less by the constraint conditions, the test question generation step selects the fill-in-the-blank words equal to or smaller than the predetermined number in accordance with predetermined priority conditions.</claim-text>
</claim>
<claim id="CLM-00007" num="00007">
<claim-text>7. The storage medium of <claim-ref idref="CLM-00006">claim 6</claim-ref>, wherein the test question generation step selects fill-in-the-blank characters by setting the priority conditions as at least one of:
<claim-text>giving priority to a noun; or</claim-text>
<claim-text>giving priority to a predefined character type among character types such as English, katakana, kanji, hiragana and the like.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00008" num="00008">
<claim-text>8. A fill-in-the-blank test question generation method comprising:
<claim-text>a pointing information extraction step performed by a pointing information extraction unit of a computer for extracting pointing information indicating a pointing position and a pointing time on a slide from slide information used in a lecture and a video image of the lecture using a pointing device;</claim-text>
<claim-text>a word information generation step performed by the pointing information extraction unit of the computer for analyzing text information extracted from the slide information to generate word information indicating a word and a position thereof;</claim-text>
<claim-text>a word pointing information generation step performed by the pointing information extraction unit of the computer for estimating a word closest to the pointing position on the slide to generate word pointing information with the pointing time assigned;</claim-text>
<claim-text>a fill-in-the-blank word extraction step performed by the pointing information extraction unit of the computer for extracting a word having a pointing time equal to or longer than a predetermined time from the word pointing information as a fill-in-the-blank word; and a test question generation step performed by the pointing information extraction unit of the computer for setting the fill-in-the-blank word of the slide information as a blank region to generate a fill-in-the-blank test question, wherein</claim-text>
<claim-text>the test question generation step performed by the pointing information extraction unit of the computer extracts a fill-in-the-blank word satisfying predetermined constraint conditions from the fill-in-the-blank word information to generate a fill-in-the-blank test question, wherein</claim-text>
<claim-text>the test question generation step performed by the pointing information extraction unit of the computer selects fill-in-the-blank characters by setting the constraint conditions as at least one of:</claim-text>
<claim-text>being equal to or smaller than the number of fill-in-the-blank words set per line;</claim-text>
<claim-text>not being adjacent to a preceding fill-in-the-blank word; and</claim-text>
<claim-text>being equal to or smaller than the number of fill-in-the-blank words set per slide page.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00009" num="00009">
<claim-text>9. The fill-in-the-blank test question generation method of <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein the word information generation step performed by the pointing information extraction unit of the computer performs a morpheme analysis of the text information to generate the word information indicating a word and a position thereof.</claim-text>
</claim>
<claim id="CLM-00010" num="00010">
<claim-text>10. The fill-in-the-blank test question generation method of <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein the pointing information extraction step performed by the pointing information extraction unit of the computer:
<claim-text>identifies a correspondence relationship with the slide information for each video frame of the video information;</claim-text>
<claim-text>detects a display time of each slide by grouping video frames for each of the slides using the identified corresponding relationship; and</claim-text>
<claim-text>extracts pointing information indicating pointing positions and pointing clock times on the slides by extracting pointing positions and extracting pointing clock times for each of the slides, which are converted into pointing positions on the identified slides.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00011" num="00011">
<claim-text>11. The method according to <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein the pointing extraction step performed by the pointing extraction unit of the computer extracts a pointing position comprising a location of a bright point of a laser pointer, a mouse cursor interlocked with mouse operation on a personal computer, a tip portion of a pointing stick and a hand or fingertip of a lecturer existing in video information.</claim-text>
</claim>
<claim id="CLM-00012" num="00012">
<claim-text>12. The method according to <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein the pointing information extraction step performed by the pointing information extraction unit of the computer detects a word closest to a pointing position for each slide, assigns a pointing time and aggregates pointing clock times of the same word to generate a pointing time for each word.</claim-text>
</claim>
<claim id="CLM-00013" num="00013">
<claim-text>13. The method according to <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein if the number of the fill-in-the-blank words is limited to a predetermined number or less by the constraint conditions, the test question generation step performed by the pointing information extraction unit of the computer selects the fill-in-the-blank words equal to or smaller than the predetermined number in accordance with predetermined priority conditions.</claim-text>
</claim>
<claim id="CLM-00014" num="00014">
<claim-text>14. The method according to <claim-ref idref="CLM-00013">claim 13</claim-ref>, wherein the test question generation step performed by the pointing information extraction unit of the computer selects fill-in-the-blank characters by setting the priority conditions as at least one of:
<claim-text>giving priority to a noun; or</claim-text>
<claim-text>giving priority to a predefined character type among character types such as English, katakana, kanji, hiragana and the like.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00015" num="00015">
<claim-text>15. A fill-in-the-blank test question generation apparatus comprising:
<claim-text>a computer executing:</claim-text>
<claim-text>a pointing information extraction unit extracting pointing information indicating a pointing position and a pointing time on a slide from slide information used in a lecture and a video image of the lecture using a pointing device;</claim-text>
<claim-text>a word information generation unit analyzing text information extracted from the slide information to generate word information indicating a word and a position thereof;</claim-text>
<claim-text>a word pointing information generation unit estimating a word closest to the pointing position on the slide to generate word pointing information with the pointing time assigned and storing the word pointing information in a storage;</claim-text>
<claim-text>a fill-in-the-blank word extraction unit reading the word pointing information from the storage, extracting a word having a pointing time equal to or longer than a predetermined time from the word pointing information as a fill-in-the-blank word and storing the extracted word into the storage; and</claim-text>
<claim-text>a test question generation unit setting the fill-in-the-blank word of the slide information as a blank region to generate a fill-in-the-blank test question, wherein the test question generation unit extracts a fill-in-the-blank word satisfying predetermined constraint conditions from the fill-in-the-blank word information to generate a fill-in the-blank test question,</claim-text>
<claim-text>wherein the test question generation unit selects fill-in-the-blank characters by setting the constraint conditions as at least one of:</claim-text>
<claim-text>being equal to or smaller than the number of fill-in-the blank words set per line;</claim-text>
<claim-text>not being adjacent to a preceding fill-in-the-blank word; and</claim-text>
<claim-text>being equal to or smaller than the number of fill-in-the-blank words set per slide page.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00016" num="00016">
<claim-text>16. The apparatus according to <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein the pointing information extraction unit extracts a pointing position comprising a location of a bright point of a laser pointer, a mouse cursor interlocked with mouse operation on a personal computer, a tip portion of a pointing stick and a hand or fingertip of a lecturer existing in video information.</claim-text>
</claim>
</claims>
</us-patent-grant>
